{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvv2116\u001b[0m (\u001b[33mnlp_final\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_split_names\n",
    "from model_vv import ModelMultitaskBinary\n",
    "from moe_vv import *\n",
    "import wandb\n",
    "wandb.login()   \n",
    "\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "parser = argparse.ArgumentParser(prog='myprogram', description='Foo')\n",
    "parser.add_argument('--expert_hidden_size', type=int, default=1024)\n",
    "parser.add_argument('--tower_hidden_size', type=int, default=1024)\n",
    "parser.add_argument('--hidden_size', type=int, default=1024) # 768 / 1024\n",
    "parser.add_argument('--bottom_hidden_size', type=int, default=1024)\n",
    "parser.add_argument('--num_experts', type=int, default=6)\n",
    "parser.add_argument('--scoring_methods', type=str, default = [\"rouge_1\",\"rogue_2\",\"rouge_l\"])\n",
    "parser.add_argument('--k', type=int, default=3)\n",
    "\n",
    "parser.add_argument('--max_len', type=int, default=448)\n",
    "parser.add_argument('--max_summ_len', type=int, default=64)\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "args.n_tasks = len(args.scoring_methods)\n",
    "args.n_positives = 1\n",
    "args.n_negatives = 1\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "args.device = device\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, default_data_collator\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from utils import *\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def nested_detach(tensors):\n",
    "        if isinstance(tensors, (list, tuple)):\n",
    "            return type(tensors)(nested_detach(t) for t in tensors)\n",
    "        return tensors.detach()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        mode = inputs[\"mode\"]\n",
    "        text_and_summaries_ids = inputs[\"text_and_summaries_input_ids\"]\n",
    "        text_and_summaries_mask = inputs[\"text_and_summaries_attn_mask\"]\n",
    "        scores = inputs[\"scores\"]\n",
    "\n",
    "        outputs = model(mode, text_and_summaries_ids, text_and_summaries_mask, scores)\n",
    "\n",
    "        loss = outputs[\"loss\"]\n",
    "        output = torch.zeros(2 + 3 * args.n_tasks + 2).float().to(loss.device)\n",
    "        output[0] = loss\n",
    "        output[1] = outputs[\"loss_nce\"]\n",
    "        for j in range(args.n_tasks):\n",
    "            output[2 + j * 3] = outputs[\"accuracy_{}\".format(args.scoring_methods[j])]\n",
    "            output[3 + j * 3] = outputs[\"rank_{}\".format(args.scoring_methods[j])]\n",
    "            output[4 + j * 3] = outputs[\"prediction_{}\".format(args.scoring_methods[j])]\n",
    "        output[-2] = outputs[\"prediction_sum\"]\n",
    "        output[-1] = outputs[\"overall_sum\"]\n",
    "        if(torch.sum(mode)) <= 0:\n",
    "            wandb.log({'r1': outputs[\"r1\"]}, commit=False)\n",
    "            wandb.log({'r2': outputs[\"r2\"]}, commit=False)\n",
    "            wandb.log({'rl': outputs[\"rl\"]}, commit=False)\n",
    "\n",
    "        \n",
    "        return (loss, output) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(\n",
    "            self,\n",
    "            model: nn.Module,\n",
    "            inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "            prediction_loss_only: bool,\n",
    "            ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Perform an evaluation step on :obj:`model` using obj:`inputs`.\n",
    "\n",
    "        Subclass and override to inject custom behavior.\n",
    "\n",
    "        Args:\n",
    "            model (:obj:`nn.Module`):\n",
    "                The model to evaluate.\n",
    "            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n",
    "            prediction_loss_only (:obj:`bool`):\n",
    "                Whether or not to return the loss only.\n",
    "            ignore_keys (:obj:`Lst[str]`, `optional`):\n",
    "                A list of keys in the output of your model (if it is a dictionary) that should be ignored when\n",
    "                gathering predictions.\n",
    "\n",
    "        Return:\n",
    "            Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss,\n",
    "            logits and labels (each being optional).\n",
    "        \"\"\"\n",
    "        has_labels = all(inputs.get(k) is not None for k in self.label_names)\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        if ignore_keys is None:\n",
    "            if hasattr(self.model, \"config\"):\n",
    "                ignore_keys = getattr(self.model.config, \"keys_to_ignore_at_inference\", [])\n",
    "            else:\n",
    "                ignore_keys = []\n",
    "\n",
    "        # labels may be popped when computing the loss (label smoothing for instance) so we grab them first.\n",
    "        if has_labels:\n",
    "            labels = nested_detach(tuple(inputs.get(name) for name in self.label_names))\n",
    "            if len(labels) == 1:\n",
    "                labels = labels[0]\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if has_labels:\n",
    "                loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
    "                loss = loss.mean().detach()\n",
    "                if isinstance(outputs, dict):\n",
    "                    logits = tuple(v for k, v in outputs.items() if k not in ignore_keys + [\"loss\"])\n",
    "                else:\n",
    "                    logits = outputs[1:]\n",
    "            else:\n",
    "                loss = None\n",
    "                if self.use_amp:\n",
    "                    # with autocast():\n",
    "                    outputs = model(**inputs)\n",
    "                else:\n",
    "                    text_inputs_ids = inputs[\"text_inputs_ids\"]\n",
    "                    text_attention_mask = inputs[\"text_attention_mask\"]\n",
    "                    text_inputs = {\n",
    "                        \"input_ids\": text_inputs_ids,\n",
    "                        \"attention_mask\": text_attention_mask\n",
    "                    }\n",
    "                    outputs = model(**text_inputs)\n",
    "                if isinstance(outputs, dict):\n",
    "                    logits = tuple(v for k, v in outputs.items() if k not in ignore_keys)\n",
    "                else:\n",
    "                    logits = outputs\n",
    "                # TODO: this needs to be fixed and made cleaner later.\n",
    "                if self.args.past_index >= 0:\n",
    "                    self._past = outputs[self.args.past_index - 1]\n",
    "\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        logits = nested_detach(logits)\n",
    "        if len(logits) == 1:\n",
    "            logits = logits[0]\n",
    "\n",
    "        return (loss, logits, labels)\n",
    "\n",
    "    def get_train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the training :class:`~torch.utils.data.DataLoader`.\n",
    "\n",
    "        Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
    "        to distributed training if necessary) otherwise.\n",
    "\n",
    "        Subclass and override this method if you want to inject some custom behavior.\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "        train_dataset = self.train_dataset\n",
    "        # if is_datasets_available() and isinstance(train_dataset, datasets.Dataset):\n",
    "        #     train_dataset = self._remove_unused_columns(train_dataset, description=\"training\")\n",
    "\n",
    "        return DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.data_collator\n",
    "        )\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    loss_nce = np.mean([preds[i] for i in range(0, len(preds), 1 + 3 * args.n_tasks + 2)])\n",
    "    result = {\n",
    "        \"loss_nce\": loss_nce\n",
    "    }\n",
    "    for j in range(args.n_tasks):\n",
    "        accuracy_arr = [preds[i] for i in range(1 + j * 3, len(preds), 1 + 3 * args.n_tasks + 2)]\n",
    "        accuracy = np.mean(accuracy_arr)\n",
    "        rank_arr = [preds[i] for i in range(2 + j * 3, len(preds), 1 + 3 * args.n_tasks + 2)]\n",
    "        rank = np.mean(rank_arr)\n",
    "        prediction_arr = [preds[i] for i in range(3 + j * 3, len(preds), 1 + 3 * args.n_tasks + 2)]\n",
    "        prediction = np.mean(prediction_arr)\n",
    "        print(\"Task {}, # pred batches: {}\".format(j + 1, len(accuracy_arr)))\n",
    "        result[\"accuracy_{}\".format(args.scoring_methods[j])] = accuracy\n",
    "        result[\"rank_{}\".format(args.scoring_methods[j])] = rank\n",
    "        result[\"prediction_{}\".format(args.scoring_methods[j])] = prediction\n",
    "    prediction_sum = np.mean([preds[i] for i in range(1 + 3 * args.n_tasks, len(preds), 1 + 3 * args.n_tasks + 2)])\n",
    "    result[\"prediction_sum\"] = prediction_sum\n",
    "    overall_sum = np.mean([preds[i] for i in range(1 + 3 * args.n_tasks + 1, len(preds), 1 + 3 * args.n_tasks + 2)])\n",
    "    result[\"overall_sum\"] = overall_sum\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27960, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/candidate_generation/candidate_scores_1.csv\")\n",
    "df[df.columns[1]] = df[df.columns[1]].apply(lambda arr : arr.split('|'))\n",
    "df[\"r1\"] = df[\"r1\"].apply(lambda arr : [100*float(val) for val in arr[2:-2].split(',')])\n",
    "df[\"r2\"] = df[\"r2\"].apply(lambda arr : [100*float(val) for val in arr[2:-2].split(',')])\n",
    "df[\"rl\"] = df[\"rl\"].apply(lambda arr : [100*float(val) for val in arr[2:-2].split(',')])\n",
    "df[\"scores\"] = df.apply(lambda row : [row[\"r1\"],row[\"r2\"],row[\"rl\"]],axis=1)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "# df[\"scores\"][0]\n",
    "\n",
    "from dataset import *\n",
    "from transformers import PegasusForConditionalGeneration,PegasusTokenizer\n",
    "\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "base_model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "train_size = 10\n",
    "val_size = 1\n",
    "xsum_train_dataset = MultitaskRerankingDatasetTrain(\"train\", tokenizer, df[df.columns[0]][:train_size].tolist(), df[df.columns[1]][:train_size].tolist(), df[df.columns[2]][:train_size].tolist(),df[\"scores\"][:train_size].tolist(), args.max_len,args.max_summ_len)\n",
    "xsum_val_dataset = MultitaskRerankingDatasetTrain(\"val\", tokenizer, df[df.columns[0]][train_size:train_size+val_size].tolist(), df[df.columns[1]][train_size:train_size+val_size].tolist(), df[df.columns[2]][train_size:train_size+val_size].tolist(),df[\"scores\"][train_size:train_size+val_size].tolist(), args.max_len,args.max_summ_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>r1</th>\n",
       "      <th>r2</th>\n",
       "      <th>rl</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>[The clean-up operation is continuing in parts...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>[0.5945945978164673, 0.523809552192688, 0.6999...</td>\n",
       "      <td>[0.5945945978164673, 0.523809552192688, 0.6999...</td>\n",
       "      <td>[0.4324324429035187, 0.3333333432674408, 0.550...</td>\n",
       "      <td>[[0.5945945978164673, 0.523809552192688, 0.699...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>[Two tourist buses have been destroyed in a su...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>[0.800000011920929, 0.9375, 0.8666666746139526...</td>\n",
       "      <td>[0.800000011920929, 0.9375, 0.8666666746139526...</td>\n",
       "      <td>[0.800000011920929, 0.9375, 0.8666666746139526...</td>\n",
       "      <td>[[0.800000011920929, 0.9375, 0.866666674613952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>[Lewis Hamilton beat Mercedes team-mate Nico R...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>[0.8823529481887817, 0.8823529481887817, 0.848...</td>\n",
       "      <td>[0.8823529481887817, 0.8823529481887817, 0.848...</td>\n",
       "      <td>[0.5882353186607361, 0.5882353186607361, 0.606...</td>\n",
       "      <td>[[0.8823529481887817, 0.8823529481887817, 0.84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>[A former Lincolnshire Police officer has gone...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>[0.39024388790130615, 0.4324324429035187, 0.38...</td>\n",
       "      <td>[0.39024388790130615, 0.4324324429035187, 0.38...</td>\n",
       "      <td>[0.3414634168148041, 0.37837839126586914, 0.33...</td>\n",
       "      <td>[[0.39024388790130615, 0.4324324429035187, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>[Turkish police have ended a siege at a psychi...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>[0.4864864945411682, 0.5714285969734192, 0.565...</td>\n",
       "      <td>[0.4864864945411682, 0.5714285969734192, 0.565...</td>\n",
       "      <td>[0.37837839126586914, 0.523809552192688, 0.478...</td>\n",
       "      <td>[[0.4864864945411682, 0.5714285969734192, 0.56...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [The clean-up operation is continuing in parts...   \n",
       "1  [Two tourist buses have been destroyed in a su...   \n",
       "2  [Lewis Hamilton beat Mercedes team-mate Nico R...   \n",
       "3  [A former Lincolnshire Police officer has gone...   \n",
       "4  [Turkish police have ended a siege at a psychi...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  Clean-up operations are continuing across the ...   \n",
       "1  Two tourist buses have been destroyed by fire ...   \n",
       "2  Lewis Hamilton stormed to pole position at the...   \n",
       "3  A former Lincolnshire Police officer carried o...   \n",
       "4  An armed man who locked himself into a room at...   \n",
       "\n",
       "                                                  r1  \\\n",
       "0  [0.5945945978164673, 0.523809552192688, 0.6999...   \n",
       "1  [0.800000011920929, 0.9375, 0.8666666746139526...   \n",
       "2  [0.8823529481887817, 0.8823529481887817, 0.848...   \n",
       "3  [0.39024388790130615, 0.4324324429035187, 0.38...   \n",
       "4  [0.4864864945411682, 0.5714285969734192, 0.565...   \n",
       "\n",
       "                                                  r2  \\\n",
       "0  [0.5945945978164673, 0.523809552192688, 0.6999...   \n",
       "1  [0.800000011920929, 0.9375, 0.8666666746139526...   \n",
       "2  [0.8823529481887817, 0.8823529481887817, 0.848...   \n",
       "3  [0.39024388790130615, 0.4324324429035187, 0.38...   \n",
       "4  [0.4864864945411682, 0.5714285969734192, 0.565...   \n",
       "\n",
       "                                                  rl  \\\n",
       "0  [0.4324324429035187, 0.3333333432674408, 0.550...   \n",
       "1  [0.800000011920929, 0.9375, 0.8666666746139526...   \n",
       "2  [0.5882353186607361, 0.5882353186607361, 0.606...   \n",
       "3  [0.3414634168148041, 0.37837839126586914, 0.33...   \n",
       "4  [0.37837839126586914, 0.523809552192688, 0.478...   \n",
       "\n",
       "                                              scores  \n",
       "0  [[0.5945945978164673, 0.523809552192688, 0.699...  \n",
       "1  [[0.800000011920929, 0.9375, 0.866666674613952...  \n",
       "2  [[0.8823529481887817, 0.8823529481887817, 0.84...  \n",
       "3  [[0.39024388790130615, 0.4324324429035187, 0.3...  \n",
       "4  [[0.4864864945411682, 0.5714285969734192, 0.56...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# loader = DataLoader(xsum_val_dataset,batch_size=1,shuffle=False)\n",
    "# x1 = next(iter(loader))\n",
    "# # from model import ModelMultitaskBinary\n",
    "# from training_utils import *\n",
    "\n",
    "# model = ModelMultitaskBinary(base_model, tokenizer, args)\n",
    "# model(x1[\"mode\"],x1[\"text_and_summaries_input_ids\"],x1[\"text_and_summaries_attn_mask\"],x1[\"scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vv2116/.local/lib/python3.8/site-packages/transformers/training_args.py:1108: FutureWarning: `--adafactor` is deprecated and will be removed in version 5 of ü§ó Transformers. Use `--optim adafactor` instead\n",
      "  warnings.warn(\n",
      "Using cuda_amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10\n",
      "  Number of trainable parameters = 583434243\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/wandb/run-20221117_112800-3mfqgtmi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nlp_final/huggingface/runs/3mfqgtmi\" target=\"_blank\">models/vtest</a></strong> to <a href=\"https://wandb.ai/nlp_final/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "tensor([44.4444, 44.4444, 44.4444])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/10 : < :, Epoch 0.10/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--HERE----\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/test.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# training loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bburstcontainer/home/vv2116/1006/cds-bootcamp/homework/nlp/NLP_Final/SummaReranker/src/summareranker/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     model\u001b[39m.\u001b[39mdisplay_training_labels()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1501\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1498\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1500\u001b[0m )\n\u001b[0;32m-> 1501\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1502\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1503\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1504\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1505\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1506\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:1826\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1823\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1826\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1828\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2089\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m   2084\u001b[0m                 eval_dataset\u001b[39m=\u001b[39meval_dataset,\n\u001b[1;32m   2085\u001b[0m                 ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2086\u001b[0m                 metric_key_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00meval_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2087\u001b[0m             )\n\u001b[1;32m   2088\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2089\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2090\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2092\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2796\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2793\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2795\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2796\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2797\u001b[0m     eval_dataloader,\n\u001b[1;32m   2798\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2799\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2800\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2801\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2802\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2803\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2804\u001b[0m )\n\u001b[1;32m   2806\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2807\u001b[0m output\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m   2808\u001b[0m     speed_metrics(\n\u001b[1;32m   2809\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2813\u001b[0m     )\n\u001b[1;32m   2814\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py:2964\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2962\u001b[0m observed_num_examples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   2963\u001b[0m \u001b[39m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 2964\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m   2965\u001b[0m     \u001b[39m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   2966\u001b[0m     observed_batch_size \u001b[39m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   2967\u001b[0m     \u001b[39mif\u001b[39;00m observed_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:668\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    667\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 668\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    669\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    672\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:706\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    705\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    708\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/data/data_collator.py:70\u001b[0m, in \u001b[0;36mdefault_data_collator\u001b[0;34m(features, return_tensors)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m# In this function we'll make the assumption that all `features` in the batch\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m# have the same attributes.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m# So we will look at the first element as a proxy for what attributes exist\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m# on the whole batch.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_default_data_collator(features)\n\u001b[1;32m     71\u001b[0m \u001b[39melif\u001b[39;00m return_tensors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m tf_default_data_collator(features)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/data/data_collator.py:119\u001b[0m, in \u001b[0;36mtorch_default_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m    117\u001b[0m     label \u001b[39m=\u001b[39m first[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(first[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m], torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m first[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    118\u001b[0m     dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlong \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(label, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mfloat\n\u001b[0;32m--> 119\u001b[0m     batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([f[\u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m f \u001b[39min\u001b[39;49;00m features], dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel_ids\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m first \u001b[39mand\u001b[39;00m first[\u001b[39m\"\u001b[39m\u001b[39mlabel_ids\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(first[\u001b[39m\"\u001b[39m\u001b[39mlabel_ids\u001b[39m\u001b[39m\"\u001b[39m], torch\u001b[39m.\u001b[39mTensor):\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "# from model import ModelMultitaskBinary\n",
    "from training_utils import *\n",
    "\n",
    "model = ModelMultitaskBinary(base_model, tokenizer, args)\n",
    "train_args = TrainingArguments(\n",
    "    output_dir=\"models/vtest\",  # will be changed\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=False,\n",
    "    num_train_epochs=1,\n",
    "    optim = \"adafactor\",\n",
    "    adafactor=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=1e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    # gradient_accumulation_steps = 3,\n",
    "    max_grad_norm=10e5,\n",
    "    fp16=True,report_to=\"wandb\",\n",
    "    logging_dir=\"logs\",\n",
    "    eval_steps=1,remove_unused_columns=False\n",
    ")\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=xsum_train_dataset,\n",
    "    eval_dataset=xsum_val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_args\n",
    ")\n",
    "\n",
    "\n",
    "# training loop\n",
    "if True:\n",
    "    trainer.train()\n",
    "    model.display_training_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>eval/loss_nce</td><td>‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñà‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÇ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñá</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÅ‚ñÑ‚ñÇ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÉ‚ñá</td></tr><tr><td>r1</td><td>‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>r2</td><td>‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>rl</td><td>‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>train/total_flos</td><td>‚ñÅ</td></tr><tr><td>train/train_loss</td><td>‚ñÅ</td></tr><tr><td>train/train_runtime</td><td>‚ñÅ</td></tr><tr><td>train/train_samples_per_second</td><td>‚ñÅ</td></tr><tr><td>train/train_steps_per_second</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_rogue_2</td><td>nan</td></tr><tr><td>eval/accuracy_rouge_1</td><td>nan</td></tr><tr><td>eval/accuracy_rouge_l</td><td>nan</td></tr><tr><td>eval/loss</td><td>0.69124</td></tr><tr><td>eval/loss_nce</td><td>0.69124</td></tr><tr><td>eval/overall_sum</td><td>nan</td></tr><tr><td>eval/prediction_rogue_2</td><td>nan</td></tr><tr><td>eval/prediction_rouge_1</td><td>nan</td></tr><tr><td>eval/prediction_rouge_l</td><td>nan</td></tr><tr><td>eval/prediction_sum</td><td>nan</td></tr><tr><td>eval/rank_rogue_2</td><td>nan</td></tr><tr><td>eval/rank_rouge_1</td><td>nan</td></tr><tr><td>eval/rank_rouge_l</td><td>nan</td></tr><tr><td>eval/runtime</td><td>0.4801</td></tr><tr><td>eval/samples_per_second</td><td>2.083</td></tr><tr><td>eval/steps_per_second</td><td>2.083</td></tr><tr><td>r1</td><td>0.72</td></tr><tr><td>r2</td><td>0.72</td></tr><tr><td>rl</td><td>0.72</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>10</td></tr><tr><td>train/total_flos</td><td>0.0</td></tr><tr><td>train/train_loss</td><td>0.69388</td></tr><tr><td>train/train_runtime</td><td>15.3774</td></tr><tr><td>train/train_samples_per_second</td><td>0.65</td></tr><tr><td>train/train_steps_per_second</td><td>0.65</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">models/vtest</strong>: <a href=\"https://wandb.ai/nlp_final/huggingface/runs/196xgsqc\" target=\"_blank\">https://wandb.ai/nlp_final/huggingface/runs/196xgsqc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221117_112547-196xgsqc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
