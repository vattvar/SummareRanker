{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import get_dataset_split_names\n",
    "xsum_dataset = load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import \n",
    "from transformers import PegasusForConditionalGeneration,PegasusTokenizer\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "\n",
    "base_model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n",
    "from dataset import *\n",
    "num_samples=204045\n",
    "val_dataset = Dataset(\"val\", tokenizer,xsum_dataset[\"train\"][\"document\"][0:] , xsum_dataset[\"train\"][\"summary\"][0:])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 5, shuffle = False)\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "model = base_model.to(device)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def beam_search_step(batch, tokenizer, base_model, device):\n",
    "    # 1 - beam search\n",
    "    if True:\n",
    "        summary_ids = base_model.generate(\n",
    "            batch[\"text_inputs\"]['input_ids'],\n",
    "            attention_mask = batch[\"text_inputs\"][\"attention_mask\"],\n",
    "            num_beams = 5,\n",
    "            num_return_sequences = 5,\n",
    "            max_length = 64\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    del summary_ids\n",
    "    gc.collect()\n",
    "\n",
    "    return generated\n",
    "\n",
    "\n",
    "def get_summaries(tokenizer, val_loader, base_model, device):\n",
    "    val_texts = []\n",
    "    val_summaries = []\n",
    "    val_labels = []\n",
    "\n",
    "    for idx, batch in tqdm(enumerate(val_loader)):\n",
    "        for k in batch[\"text_inputs\"].keys():\n",
    "            batch[\"text_inputs\"][k] = batch[\"text_inputs\"][k].to(device)\n",
    "            if len(batch[\"text_inputs\"][k].shape) > 2:\n",
    "                batch[\"text_inputs\"][k] = batch[\"text_inputs\"][k].squeeze(1)\n",
    "\n",
    "        model.zero_grad()\n",
    "        val_texts += batch[\"text\"]\n",
    "\n",
    "        raw_summaries = beam_search_step(batch, tokenizer, base_model, device)\n",
    "        \n",
    "        summaries = []\n",
    "        for i in range(len(batch[\"text\"])):\n",
    "            summaries.append(\"|\".join(raw_summaries[i*5:(i+1)*5]))\n",
    "\n",
    "        val_summaries += summaries\n",
    "\n",
    "        labels = batch[\"summary\"]\n",
    "        val_labels += labels\n",
    "        df = pd.DataFrame({\"text\": batch[\"text\"],\"summaries\":summaries,\"labels\":labels})\n",
    "        df.to_csv(\"candidates_1.csv\",mode='a',index=False,header=False)\n",
    "\n",
    "        # with open(f\"candidates_txt\", 'a+b') as fp:\n",
    "        #     pickle.dump(val_texts,fp)\n",
    "        # with open(f\"candidates_summary\", 'a+b') as fp:\n",
    "        #     pickle.dump(val_summaries,fp)\n",
    "        # with open(f\"candidates_label\", 'a+b') as fp:\n",
    "        #     pickle.dump(val_labels,fp)\n",
    "\n",
    "    # print(len(val_texts), len(val_summaries), len(val_summaries[0]), len(val_labels))\n",
    "\n",
    "    # return val_texts, val_summaries, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_summaries(tokenizer, val_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"candidates_1.csv\",header=None)\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
